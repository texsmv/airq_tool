{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "from datetime import datetime, timedelta\n",
    "from source.utils import CO_MOLECULAR_WEIGHT, NO2_MOLECULAR_WEIGHT, O3_MOLECULAR_WEIGHT, SO2_MOLECULAR_WEIGHT, dfMonthWindows, dfDailyWindows, dfYearWindows, ppb_to_ug_per_m3, ppm_to_ug_per_m3, tryFillMissing\n",
    "DB_PATH = 'datasets/ontario/'\n",
    "\n",
    "# granularity = 'months'\n",
    "granularity = 'daily'\n",
    "fill_missing = True\n",
    "max_missing = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    }
   ],
   "source": [
    "years = ['2020']\n",
    "# pollutants = ['NO', 'NOx', 'NO2', 'SO2', 'CO', 'O3', 'PM25']\n",
    "pollutants = ['PM25', ]\n",
    "\n",
    "\n",
    "\n",
    "windows_map = {}\n",
    "windows_original_map = {}\n",
    "for pollutant in pollutants:\n",
    "    conc_map = {}\n",
    "    conc_original_map = {}\n",
    "    aux_map = {}\n",
    "    for i in range(len(years)):\n",
    "        with open(os.path.join(DB_PATH, \"{}-{}.csv\".format(pollutant, years[i])), \"r\") as f:\n",
    "            data = f.read()\n",
    "        print(years[i])\n",
    "        slices = data.split(\"\\n\\n\")\n",
    "        for slice in slices:\n",
    "            pos = slice.find('Station ID')\n",
    "            if pos != -1:\n",
    "                content = slice[pos:]\n",
    "                content = content.replace(',\\n', '\\n')\n",
    "                content = content[:-1]\n",
    "                df = pd.read_csv(io.StringIO(content), sep=',', header =0)\n",
    "                station = df['Station ID'][0]\n",
    "                \n",
    "            \n",
    "                hours = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24']\n",
    "                hoursD = ['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23']\n",
    "                values = np.zeros((365, 24))\n",
    "                dates = []\n",
    "                for index, row in df.iterrows():\n",
    "                    # print('-')\n",
    "                    # print(index)\n",
    "                    if index < 365:\n",
    "                        for k in range(len(hours)):\n",
    "                            values[index][k] = (row['H{}'.format(hours[k])])\n",
    "                            if granularity == 'daily':\n",
    "                                if k == 0:\n",
    "                                    date = datetime.strptime('{} 00:00:00'.format(row['Date']), '%Y-%m-%d %H:%M:%S')\n",
    "                                else:\n",
    "                                    date = date + timedelta(hours=1)\n",
    "                                if date in dates:\n",
    "                                    # ! FIX for dates error on csv\n",
    "                                    dates.append(date + timedelta(days=1))\n",
    "                                else:\n",
    "                                    dates.append(date)\n",
    "                            else:\n",
    "                                if k == 0:\n",
    "                                    dateStr = '{}T{}:00:00.000000000'.format(row['Date'], hoursD[k])\n",
    "                                    date = np.datetime64(dateStr)\n",
    "                                    # date = pd.to_datetime(dateStr, infer_datetime_format=True)\n",
    "                                    dates.append(date)\n",
    "                                    # break\n",
    "                values[values==9999]=np.nan\n",
    "                values[values==-999]=np.nan\n",
    "                \n",
    "                if granularity != 'daily':\n",
    "                    # print(values)\n",
    "                    values = np.mean(values, axis=1)\n",
    "                    # print(values.shape)\n",
    "                    if fill_missing:\n",
    "                        values = tryFillMissing(values,  maxMissing=max_missing)\n",
    "                else:\n",
    "                    for t in range(len(values)):\n",
    "                        if fill_missing:\n",
    "                            # print(values[t].shape)\n",
    "                            values[t] = tryFillMissing(values[t], maxMissing=max_missing)\n",
    "                    values = values.flatten()\n",
    "                        \n",
    "                values = values[:len(dates)]\n",
    "                # print(values)\n",
    "                dates = np.array(dates)\n",
    "                \n",
    "                if  station not in aux_map:\n",
    "                    aux_map[station] = {}\n",
    "                \n",
    "                if pollutant not in aux_map[station]:\n",
    "                    aux_map[station][pollutant] = (values, dates)\n",
    "                else:\n",
    "                    currValues, currDates = aux_map[station][pollutant]\n",
    "                    aux_map[station][pollutant] = (np.concatenate([currValues, values], axis=0), np.concatenate([currDates, dates], axis=0))\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  2.,  2.,  3.,  3.,  2.,  2.,  2.,  3.,  3.,  2.,  2.,  3.,\n",
       "        3.,  5.,  5.,  6.,  7.,  9., 11., 13., 11., 13., 11.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aux_map[47045]['PM25'][0][:24]\n",
    "# aux_map[47045]['PM25'][1][:24]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.208333333333333"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# station = stations[0]\n",
    "# values, pol_datetimes = aux_map[station][pollutant]\n",
    "# df_conc = pd.DataFrame({'date': pol_datetimes, 'value': values})\n",
    "# df_conc = df_conc.set_index('date')\n",
    "# # values, dates = dfDailyWindows(df_conc, fill_missing=fill_missing, maxMissing=max_missing)\n",
    "# values, dates = dfMonthWindows(df_conc, fill_missing=fill_missing, maxMissing=max_missing)\n",
    "# # values, dates = dfYearWindows(df_conc, fill_missing=fill_missing, maxMissing=max_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
