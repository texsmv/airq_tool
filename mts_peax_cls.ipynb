{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-13 10:13:15.373516: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from source.tserie import TSerie\n",
    "from source.keras_utils import getPeaxFeatures\n",
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.datasets import loadFuncionalModel, loadNatops, loadWafer, loadSelfRegulationSCP2, loadBasicMotions, loadEarthquakes, loadItalyPowerDemand, loadEigenWorms\n",
    "\n",
    "dataset = 'natops' # natops | wafer | selfreg | basicmotions | earthquakes | italy | eigenworms\n",
    "\n",
    "settings = {\n",
    "    'natops' : {\n",
    "        'epochs': 200,\n",
    "        'filters' : [16, 32],\n",
    "        'kernels' : [5, 5],\n",
    "        'feat_size' : 15,\n",
    "    },\n",
    "    'wafer' : {\n",
    "        'epochs': 50,\n",
    "        'filters' : [16, 32],\n",
    "        'kernels' : [5, 5],\n",
    "        'feat_size' : 20,\n",
    "    },\n",
    "    'basicmotions' : {\n",
    "        'epochs': 300,\n",
    "        'filters' : [16, 32],\n",
    "        'kernels' : [5, 5],\n",
    "        'feat_size' : 20,\n",
    "    },\n",
    "    'italy' : {\n",
    "        'epochs': 200,\n",
    "        'filters' : [16],\n",
    "        'kernels' : [5],\n",
    "        'feat_size' : 20,\n",
    "    }\n",
    "}\n",
    "\n",
    "if dataset == 'natops':\n",
    "    X_train, y_train, X_test, y_test, classLabels = loadNatops()\n",
    "elif dataset == 'wafer':\n",
    "    X_train, y_train, X_test, y_test = loadWafer()\n",
    "    classLabels = {}\n",
    "elif dataset == 'basicmotions':\n",
    "    X_train, y_train, X_test, y_test, classLabels= loadBasicMotions()\n",
    "elif dataset == 'italy':\n",
    "    X_train, y_train, X_test, y_test, classLabels= loadItalyPowerDemand()\n",
    "# X = np.concatenate([X_train, X_test], axis=0).transpose([0, 2, 1])\n",
    "# y = np.concatenate([y_train, y_test], axis=0)\n",
    "# y = np.array([float(v) for v in y]).astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded mts - N: 180, T: 51, D: 24 \n",
      "Loaded mts - N: 180, T: 51, D: 24 \n"
     ]
    }
   ],
   "source": [
    "mts_train = TSerie(X=X_train.transpose([0, 2, 1]), y=y_train)\n",
    "mts_test = TSerie(X=X_test.transpose([0, 2, 1]), y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mts.smooth(window_size=40)\n",
    "# mts.shapeNormalizization()\n",
    "minl, maxl = mts_train.minMaxNormalizization()\n",
    "minl, maxl = mts_test.minMaxNormalizization(minl= minl, maxl=maxl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-13 10:13:19.125539: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-09-13 10:13:19.126565: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-09-13 10:13:19.954300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-13 10:13:19.954683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce MX450 computeCapability: 7.5\n",
      "coreClock: 1.575GHz coreCount: 14 deviceMemorySize: 1.83GiB deviceMemoryBandwidth: 52.17GiB/s\n",
      "2022-09-13 10:13:19.954751: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-09-13 10:13:19.972679: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-09-13 10:13:19.972891: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-09-13 10:13:19.983150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-09-13 10:13:19.986808: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-09-13 10:13:20.003161: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-09-13 10:13:20.006188: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-09-13 10:13:20.035268: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-09-13 10:13:20.035774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-13 10:13:20.036178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-13 10:13:20.036336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-09-13 10:13:20.036708: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-13 10:13:20.037091: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-09-13 10:13:20.037243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-13 10:13:20.037409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce MX450 computeCapability: 7.5\n",
      "coreClock: 1.575GHz coreCount: 14 deviceMemorySize: 1.83GiB deviceMemoryBandwidth: 52.17GiB/s\n",
      "2022-09-13 10:13:20.037460: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-09-13 10:13:20.037489: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-09-13 10:13:20.037503: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-09-13 10:13:20.037518: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-09-13 10:13:20.037532: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-09-13 10:13:20.037545: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-09-13 10:13:20.037562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-09-13 10:13:20.037577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-09-13 10:13:20.037635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-13 10:13:20.037771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-13 10:13:20.037865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-09-13 10:13:20.038179: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-09-13 10:13:20.757218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-09-13 10:13:20.757252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-09-13 10:13:20.757257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-09-13 10:13:20.757791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-13 10:13:20.757984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-13 10:13:20.758115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-13 10:13:20.758210: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-09-13 10:13:20.758231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1452 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce MX450, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2022-09-13 10:13:20.948480: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-09-13 10:13:20.950450: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2918400000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d (Cropping1D)      (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d (Cropping1D)      (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-13 10:13:21.759450: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-09-13 10:13:22.027841: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 45ms/step - loss: 2.4747\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.4580\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.2170\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.4260\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.2194\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.1646\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.2234\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.0396\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.2787\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.7694\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.4021\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9680\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.0451\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4192\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9868\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3094\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7616\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1067\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0135\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1343\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8496\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9875\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0331\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7843\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0356\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0304\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5843\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5632\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5974\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7701\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5953\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6715\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6159\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4449\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4045\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9293\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5547\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3906\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4164\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5756\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3471\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3948\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4300\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3923\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3473\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5384\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4346\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4204\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3113\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3199\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3421\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5321\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3236\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4141\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3687\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3009\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2835\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2737\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3241\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4405\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2966\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2597\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2889\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2776\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3125\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2776\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3275\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4276\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3047\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3519\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4556\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2492\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2520\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2334\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2659\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3628\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3652\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3780\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3005\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2443\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2469\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2441\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2958\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2300\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2179\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2821\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3289\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2757\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2603\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2115\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2417\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2484\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3598\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2604\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2439\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1979\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2209\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2538\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2304\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2990\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2943\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2139\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2705\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3418\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2931\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2284\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2190\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2005\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2028\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1956\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2035\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2631\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2106\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2240\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2399\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2617\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2071\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2128\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2040\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1931\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1876\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2138\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2336\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2754\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3116\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1975\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1966\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1783\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1977\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1870\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2158\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2577\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2354\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3184\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2273\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1772\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1678\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1622\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1741\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1965\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2004\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2342\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1740\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1596\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1759\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1882\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1802\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2793\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2407\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1580\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1479\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1498\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1603\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1499\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1784\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1899\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1696\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1976\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2313\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1637\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1626\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1488\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1614\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1429\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2046\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2634\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1650\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1639\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1334\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1431\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1356\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1593\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1656\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1762\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2286\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1402\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1464\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1439\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1311\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1255\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1786\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1816\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1767\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1809\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1462\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1403\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1479\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1469\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1456\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2067\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1606\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1345\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1426\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1413\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1307\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1489\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1631\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2155\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1362\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1308\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_1 (Cropping1D)    (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_1 (Cropping1D)    (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 8.9514\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.6408\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.6489\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.1778\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.3627\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.4843\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.4305\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.8819\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.6469\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.9019\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.5410\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.4429\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5913\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5186\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6596\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3793\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.4337\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5135\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3934\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1581\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0257\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.2648\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0670\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4105\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0605\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8023\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4817\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9233\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4733\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9226\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6564\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0953\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6905\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5549\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2782\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9266\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5728\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1402\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6865\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6686\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5071\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6314\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0031\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5137\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5547\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0220\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5270\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4413\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4391\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7902\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5325\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3512\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4965\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6536\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4882\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6407\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7825\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4149\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3929\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4826\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5958\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4942\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4392\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3674\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4468\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5862\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4363\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3759\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3168\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3110\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4700\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4495\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3298\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4266\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5805\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3807\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4164\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5144\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3163\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3337\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3641\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3890\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3902\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4646\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3714\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3051\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3147\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5380\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4080\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3751\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3996\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2927\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3239\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3476\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4023\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3351\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3478\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3826\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3576\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4040\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2991\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2851\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3201\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3437\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2946\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3166\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3256\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3360\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4003\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2675\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2885\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2940\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2926\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3074\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3190\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3912\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3634\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3287\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2524\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2682\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2400\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2244\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2198\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2777\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3661\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3059\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2775\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3114\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3227\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2683\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2727\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3313\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2898\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2598\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2786\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3139\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2296\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2329\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2918\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2585\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2229\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2071\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1966\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2043\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2067\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1961\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2235\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2107\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2668\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3833\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3323\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2700\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2282\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2280\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2503\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2474\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1991\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2050\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3304\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2401\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2232\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2428\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2528\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2880\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2025\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2208\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2204\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2332\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2162\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2534\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2349\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1799\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1774\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1969\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2398\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2336\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2243\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2315\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2501\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2241\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2158\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2463\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2213\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2288\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2164\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2160\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1915\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1921\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2118\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2648\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2191\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1827\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1985\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1830\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1986\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1951\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2153\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2479\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2735\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2262\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_2 (Cropping1D)    (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_2 (Cropping1D)    (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 0.9919\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9859\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0329\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0638\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0042\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9880\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9435\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0231\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9202\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9480\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9366\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9769\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.0623\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9922\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9284\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1519\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9619\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1247\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9652\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0497\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0427\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9936\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9780\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9274\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9659\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0666\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9939\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9774\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9352\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9997\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9796\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9018\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9614\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0358\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9063\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9593\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0303\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9618\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0162\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8150\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9285\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0415\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9492\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8144\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1108\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.8414\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9619\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0967\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0722\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9828\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9717\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9049\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9025\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0233\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9902\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9133\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8519\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8006\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7664\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9549\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9722\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9693\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7980\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8453\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.7800\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0696\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0213\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7486\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7375\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9226\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8097\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6733\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0419\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7077\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7151\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6808\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7506\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7306\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7373\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7994\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6803\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7227\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.0459\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7233\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6516\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6845\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8220\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6449\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6657\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5651\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7825\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6998\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6533\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6606\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6734\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6459\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6618\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5579\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7127\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5649\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5378\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7539\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6802\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5297\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5091\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6841\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5177\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6146\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6846\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4879\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4842\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6037\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5090\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5092\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5372\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5992\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5684\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5278\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6677\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4660\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5640\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5006\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4727\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5791\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4870\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4591\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5412\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4635\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4219\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4230\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5292\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4257\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4160\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4173\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4946\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4266\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4791\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3852\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4221\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3940\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3794\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4141\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4927\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4188\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3784\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3820\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4745\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4154\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4076\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4174\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4627\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3774\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4058\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3722\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3995\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4028\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4590\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4483\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4231\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3557\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3397\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4187\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3820\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4381\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4174\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3742\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3484\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4287\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4420\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3685\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4153\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3422\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4678\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3656\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3667\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3482\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3413\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3660\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4571\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3233\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3387\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3366\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3295\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3759\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3707\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4054\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4035\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3535\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3313\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3714\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4465\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3286\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3013\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3079\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3199\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3015\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3714\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3920\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3603\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3379\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_3 (Cropping1D)    (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_3 (Cropping1D)    (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 4.6903\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 4.4379\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.1136\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.5489\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.3963\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.2652\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.4206\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3.2029\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.3127\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.1463\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.0714\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.3098\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.0033\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.6767\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.5195\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.6980\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.9138\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.9647\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7556\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.5419\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.9845\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.3553\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3506\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.8548\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.5573\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.1343\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4042\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2006\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3519\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4658\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.7318\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0649\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1511\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5882\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3915\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2554\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9516\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9560\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9538\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0928\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9880\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0441\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0512\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9722\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9796\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8812\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8400\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9406\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9546\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8713\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8869\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1870\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8791\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7821\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8227\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0614\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9126\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8503\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8470\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8421\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8013\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7648\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8667\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8227\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8248\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8506\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7899\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7627\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7556\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8100\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8316\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7367\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7107\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6792\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7274\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7485\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.669 - 0s 5ms/step - loss: 0.6915\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7271\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7579\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7225\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6654\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6049\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6505\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7490\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6640\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5788\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6001\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6931\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6349\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6410\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6404\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6501\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6026\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5817\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6134\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6449\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5862\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5345\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5924\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6286\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4750\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4634\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6115\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6202\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5576\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6048\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4619\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5445\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6266\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4498\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3652\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3922\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5093\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6373\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4622\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4994\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4725\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3990\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3852\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4650\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5125\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3510\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3690\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3382\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3890\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3815\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3470\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5464\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4131\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3892\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3564\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3242\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3804\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4142\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4355\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3323\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3271\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3485\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3346\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3647\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3766\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3184\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3513\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3886\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3177\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2654\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3514\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4109\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3475\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3150\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3163\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3010\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3205\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2802\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2715\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2853\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2887\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2996\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2943\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2663\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2662\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3143\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2760\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2644\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2507\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3206\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2845\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2609\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2235\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2572\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2661\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2413\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2578\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3262\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2769\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2598\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2724\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2453\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2338\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2767\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2586\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2483\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2369\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2953\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2452\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2227\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2227\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1804\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2108\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1946\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2333\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2645\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2469\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3243\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2543\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2919\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2405\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1767\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1793\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2146\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_4 (Cropping1D)    (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_4 (Cropping1D)    (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 6.9172\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.1196\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 4.2051\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.1205\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.9731\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8895\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.9755\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7590\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.0064\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.2410\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.7418\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.2063\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8452\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.8964\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.6942\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.6956\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9576\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.4331\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.1441\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.0523\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.7636\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.1124\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6447\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.5226\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5199\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6629\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6026\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.5006\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4075\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4674\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.3629\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4523\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3595\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.9066\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2224\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3701\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3138\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4520\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3538\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2169\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3734\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2968\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.4344\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3284\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2058\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0797\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1653\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3652\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2331\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2356\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3408\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1642\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0315\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0545\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2395\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1674\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1336\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0817\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0445\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0537\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1353\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2005\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1853\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0751\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0363\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9439\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0102\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0032\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0277\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9908\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1141\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0850\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0437\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0012\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9720\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9646\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9128\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9880\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1899\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0177\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9321\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9274\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9690\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9557\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9687\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8818\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9027\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0681\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0832\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8794\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9497\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9586\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8623\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8855\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9684\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8762\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7915\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8349\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9499\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8386\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8544\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7791\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8490\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7164\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6661\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8493\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7792\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5886\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0254\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7619\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6078\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5354\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5812\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0012\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5500\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5046\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5258\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5855\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6767\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1575\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5410\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4901\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4870\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4731\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4768\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6605\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7942\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5442\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4926\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5649\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5874\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4794\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4256\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4448\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7610\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4853\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4093\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5095\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5248\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3976\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3686\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4431\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6388\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6820\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3992\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3761\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4103\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4086\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5143\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5916\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4113\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3207\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3638\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4774\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4065\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3488\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4957\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3868\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3309\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3160\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3873\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4638\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4052\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4081\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3996\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3599\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3200\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2871\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2798\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2845\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3303\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3804\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4786\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4844\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3704\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3352\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3212\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3002\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2971\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2905\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4011\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4031\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3110\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2677\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2740\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3193\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3112\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3175\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3171\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2835\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2727\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2762\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2763\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.458 - 0s 6ms/step - loss: 0.4943\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4446\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2795\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2771\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2891\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3167\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2854\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_5 (Cropping1D)    (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_5 (Cropping1D)    (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 1.9972\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9587\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7882\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6636\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6480\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.6602\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6987\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7004\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.5867\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6655\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6585\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5759\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6330\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6199\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6925\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6448\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6675\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5535\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.6449\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6351\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6471\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6261\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.7366\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6444\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.5923\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6537\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.6280\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5968\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.9454\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.5202\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5963\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4883\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6986\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5094\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.3441\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.0129\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4591\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.6361\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4893\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.5258\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5317\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2208\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2977\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0553\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5024\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0074\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.5884\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1367\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8658\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1090\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9208\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8559\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6186\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.1938\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9130\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7284\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7227\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0010\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7923\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0071\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7609\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6721\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7947\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7018\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.7208\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7144\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5934\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7281\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8333\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5746\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8283\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8674\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5276\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5293\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9347\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7850\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5471\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.703 - 0s 9ms/step - loss: 0.6803\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5754\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5297\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5704\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6795\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5555\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4679\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4828\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4982\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7003\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4716\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4335\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5017\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4588\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4308\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5618\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5703\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4687\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4708\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4401\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4316\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5060\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5143\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4440\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4142\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4018\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4148\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4027\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4044\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4359\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6446\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4087\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4279\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5273\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4394\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3814\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3622\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3781\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3927\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5148\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4106\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3845\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3800\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3902\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3803\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3488\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3488\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3822\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4101\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4022\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4186\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4594\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3576\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3390\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3265\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3288\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3191\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2988\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3202\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4017\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3926\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3316\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3478\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3171\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2925\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3133\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2948\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3141\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3078\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3239\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4225\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3381\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3287\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3049\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2690\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2658\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2745\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2933\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4106\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3247\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3041\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2678\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2626\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2595\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2485\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2534\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3083\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3204\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3299\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2579\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2456\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2490\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2695\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2831\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2726\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2588\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2968\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2544\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2647\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2607\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2923\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2759\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2619\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2447\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2569\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2821\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3028\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2937\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2519\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2441\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2689\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2824\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2564\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2233\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2160\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2075\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2429\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2791\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2150\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2253\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2608\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2546\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2422\n",
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_6 (Cropping1D)    (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_6 (Cropping1D)    (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 1.4385\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1768\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2291\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0941\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.0499\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0942\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0048\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0104\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0903\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0397\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9735\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9168\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4974\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1486\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0636\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0834\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0905\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9837\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0505\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8751\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9782\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9475\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9362\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7870\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8986\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7931\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6710\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8885\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5979\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6531\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5958\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5991\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5259\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5371\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4048\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5091\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5620\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4609\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4989\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4243\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3921\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3715\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4966\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4083\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3693\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3419\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3518\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3902\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3040\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3082\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3302\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2881\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2934\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3024\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3489\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3602\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3290\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3565\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3000\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3120\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2968\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3654\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3208\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2680\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3100\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2900\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2844\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3049\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2753\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2872\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2960\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3657\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2942\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2678\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2718\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3053\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2669\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2695\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2735\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3018\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2547\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2677\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3588\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2858\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2478\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2960\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2417\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2443\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2802\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2499\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2410\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3092\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2324\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2354\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2304\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2679\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2459\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2204\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2281\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3171\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2492\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2071\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2249\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2917\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2577\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2018\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2166\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2946\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1997\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1912\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1983\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2562\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3063\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2227\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2041\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1799\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2251\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2080\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1931\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2353\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2212\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2018\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1908\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1973\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1709\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2548\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2003\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1674\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1885\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3675\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1779\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1831\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2086\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2030\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2019\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1563\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1819\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2005\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1574\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1551\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2714\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1868\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1504\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1622\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1852\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1667\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1520\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1401\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2847\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1545\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1368\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1274\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1593\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1595\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2093\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1346\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1370\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1736\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1821\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1439\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1244\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1360\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1493\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1530\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2048\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1630\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1796\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1288\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1422\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1676\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1393\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1186\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1403\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1282\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1854\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1506\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1882\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1306\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1215\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1446\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1698\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1134\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1218\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1402\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1589\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1348\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1451\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1217\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1140\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1598\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1317\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1465\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1536\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1354\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1132\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1213\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1563\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1013\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1074\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1023\n",
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_7 (Cropping1D)    (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_7 (Cropping1D)    (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 3.0782\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.8612\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.5925\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.0268\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0369\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0055\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8268\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.7731\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.8676\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7612\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.7662\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.8198\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7985\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.7309\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.9054\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6473\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3341\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.9396\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8872\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.7732\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.7608\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.7969\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5863\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6272\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5266\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6770\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4394\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2725\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6655\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.1277\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1283\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7316\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1534\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9657\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9462\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3504\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4671\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9907\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7594\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7782\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7387\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7323\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7122\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7706\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7210\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6618\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6920\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6000\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6070\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.7664\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7096\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5488\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6168\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6159\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4296\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4313\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5577\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6063\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6363\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4559\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4254\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4664\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5204\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5257\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4072\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3734\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4667\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5105\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5748\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3889\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3304\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3277\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3429\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6934\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3958\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3504\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3839\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3149\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4082\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3861\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5087\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4286\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3267\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3268\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3888\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2960\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3189\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2994\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3953\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2862\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3204\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4149\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3298\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2951\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3239\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3204\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2864\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2635\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2427\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2575\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3266\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3453\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3733\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2856\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2395\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2349\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2632\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3753\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3857\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2532\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2326\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2243\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2622\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3187\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2771\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2291\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2193\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2046\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2663\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2874\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3029\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2540\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2289\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2058\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2509\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3258\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2706\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2595\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2157\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2001\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2207\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2652\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2934\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2474\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2179\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1952\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2015\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2254\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2705\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2475\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2239\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1901\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1700\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1854\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2821\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2308\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1706\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1649\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1639\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2159\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2903\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2044\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1588\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1530\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1887\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1555\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1765\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2223\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2159\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1799\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1496\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1399\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1448\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1468\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1657\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2246\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1927\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2233\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1680\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1914\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1898\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1890\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1491\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1316\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1363\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1635\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1534\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1354\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1637\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1617\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1608\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1806\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1535\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1287\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1186\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1319\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1359\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1575\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1845\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2052\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1863\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1461\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1375\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1281\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1635\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1685\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1562\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1545\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1722\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1577\n",
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_8 (Cropping1D)    (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_8 (Cropping1D)    (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 2.5012\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.3829\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.6485\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.6771\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2453\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3632\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1976\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2195\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2781\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3156\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0743\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1656\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2471\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2858\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.3031\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3993\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9691\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1256\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0242\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1813\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0479\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9293\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4370\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0641\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4615\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.1422\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2634\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0762\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1218\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7977\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2287\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2344\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1156\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8161\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0054\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.3482\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8106\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1473\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8992\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6750\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1484\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8014\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1124\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9545\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3129\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7046\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.0074\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.721 - 0s 7ms/step - loss: 0.7514\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.0346\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8836\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9858\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6279\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4301\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7124\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7519\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5035\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4242\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4885\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2104\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5261\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4260\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3757\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3886\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7890\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5082\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3640\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3315\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5157\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7308\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4322\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4905\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4014\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5695\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3935\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4060\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5865\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3934\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3869\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5537\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4627\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3355\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3145\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3360\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5807\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5197\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3623\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3531\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3491\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4431\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3693\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4644\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4125\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3616\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3349\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3308\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4544\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3902\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3435\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3586\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5391\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2862\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2098\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2543\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5460\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4811\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2699\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2460\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2480\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4503\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3950\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2956\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2024\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2239\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2139\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3324\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4732\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3342\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2885\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2786\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2741\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3690\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3658\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2619\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3054\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4145\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2638\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2443\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2059\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2214\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2645\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2976\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3497\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2811\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2569\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3094\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2645\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2670\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2804\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2300\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2314\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2283\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3210\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4019\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2394\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1812\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1903\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1838\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1776\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2146\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3305\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2666\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2289\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2392\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2781\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2853\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2527\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2819\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1863\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2275\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2874\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2368\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2391\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2207\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2284\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2257\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2143\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2846\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2258\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2103\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1822\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1781\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1845\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1926\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2205\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2239\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1949\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2223\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2270\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1986\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1835\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2095\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1727\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1751\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1879\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2359\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1729\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.145 - 0s 5ms/step - loss: 0.1449\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1432\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1880\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2158\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2691\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1789\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1502\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1413\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1225\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1482\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1925\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2912\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1772\n",
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_9 (Cropping1D)    (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_9 (Cropping1D)    (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 1.1639\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1104\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0119\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8913\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7808\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7706\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7656\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7702\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7391\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7507\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7811\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7774\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7026\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7543\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8009\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8428\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7088\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7771\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.7135\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8082\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7003\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7648\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6500\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6111\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7124\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6301\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6318\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5919\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5686\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6633\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5237\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5273\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5725\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5023\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4531\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5923\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5742\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4150\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3946\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4556\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4237\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4969\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4309\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4000\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4668\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4274\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4441\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4804\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3485\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3740\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3743\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3757\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3324\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4751\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3299\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4007\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3530\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4934\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3480\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3702\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3917\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2965\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4582\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3301\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3382\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2833\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3433\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3716\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2973\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2754\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3441\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3422\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3541\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3484\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2969\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3739\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3104\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3355\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2835\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2886\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3976\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2792\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2417\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2894\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2740\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3234\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2431\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2529\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2643\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2747\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3634\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3450\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2928\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2561\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2585\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2318\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3422\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2480\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2672\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2829\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2861\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2205\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2795\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2097\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1999\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2513\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3726\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2318\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2705\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2672\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2293\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1969\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2892\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2497\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2079\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1940\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2309\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2222\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2405\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1917\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1824\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1960\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2603\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1936\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2193\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2081\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2060\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2301\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1702\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2195\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2695\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2551\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1837\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1743\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2107\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1706\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2465\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1945\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2125\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2442\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1709\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1650\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2451\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1677\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1674\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1401\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2029\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1490\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1434\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2715\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1576\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1642\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2026\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1635\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1882\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1652\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1372\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1623\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1339\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1457\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2811\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1411\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1382\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1556\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1945\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1290\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1515\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1743\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1526\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1446\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1969\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1747\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1398\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1293\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1385\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1900\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1874\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1158\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1147\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1168\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1694\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1720\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1219\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1199\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1398\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1553\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1914\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1215\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1313\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1305\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1535\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2070\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1299\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1206\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1129\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1060\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1122\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0978\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1559\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2072\n",
      "Model: \"model_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_10 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_10 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 2.9090\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.6238\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.8606\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.9388\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.5921\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.6443\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6752\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.5762\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6635\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5759\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4606\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6912\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3425\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3747\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2687\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.7211\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.1001\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8617\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9256\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0834\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5024\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9430\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8852\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7650\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9232\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9101\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7648\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8355\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6754\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8468\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6580\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7288\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7697\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5814\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6197\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6479\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7925\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5142\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5670\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6311\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6355\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6218\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7310\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7256\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5735\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6011\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5059\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5717\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7136\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4986\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4439\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4935\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5235\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7824\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4972\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4785\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4935\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5446\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4484\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5650\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4885\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4906\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6262\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5841\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5369\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4239\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4128\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4046\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3987\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4169\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8051\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6383\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4321\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4109\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3787\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5039\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6910\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4227\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3618\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3516\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3495\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3797\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3968\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6592\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3723\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3643\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3669\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3772\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5060\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5363\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4166\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3668\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3443\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3289\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4792\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5017\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3789\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3749\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3612\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3283\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3636\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6476\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4219\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3900\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3603\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4368\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4268\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3369\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3469\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5044\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4050\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3529\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3312\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3061\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2968\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3722\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5106\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4126\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2984\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2944\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3086\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3847\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4515\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3516\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3601\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2970\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3339\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4236\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3915\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3537\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3896\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4096\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3155\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3182\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3205\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3583\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4019\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3576\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3281\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3399\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3197\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4210\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3753\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3265\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3752\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3400\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3648\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4169\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3544\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3147\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2985\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2990\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3450\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4273\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3316\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3191\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3291\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3790\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3018\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2796\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2505\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2672\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2886\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3188\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3283\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3636\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2923\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3304\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2831\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3057\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2687\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2664\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3225\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3284\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3236\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2485\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2161\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2590\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2694\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2130\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2442\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3912\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2626\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2586\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2516\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2507\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3031\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2483\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2516\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2297\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2198\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2365\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2736\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2071\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1843\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2062\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2979\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2405\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1981\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2023\n",
      "Model: \"model_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_11 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_11 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 2.4715\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.3204\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.3846\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.2767\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2.0466\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.9643\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.2687\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.0075\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.0290\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.2587\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2.0127\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.6828\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.3552\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.660 - 0s 10ms/step - loss: 1.5726\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.0871\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.9003\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.2122\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3087\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.4675\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.1921\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.8044\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.8113\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.1172\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.3354\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.0990\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8391\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.2919\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.1930\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9826\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.2747\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8776\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1162\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.1849\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.8068\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8236\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9264\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.4836\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9402\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9420\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0081\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3227\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7095\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7214\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.2978\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9205\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7507\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.0985\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7686\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8135\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.9598\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6667\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6511\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8416\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6822\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.2057\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6056\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5342\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6581\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1791\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5880\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8912\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9621\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4722\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4436\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4577\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7763\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5185\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6583\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7374\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6796\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4097\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4239\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4159\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4547\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6790\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3623\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3456\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3358\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3833\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9157\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4439\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4640\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6055\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4330\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3641\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5217\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4392\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2910\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3025\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6388\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3723\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3243\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3972\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3510\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3660\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3780\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4793\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2866\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4423\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4676\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2967\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3285\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2608\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2592\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2671\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2724\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4245\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4164\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3294\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2777\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4311\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3917\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3380\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3713\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2755\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2571\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2609\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2581\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2470\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1962\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2234\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2726\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2262\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2255\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2383\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2025\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2241\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3884\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3413\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3001\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2740\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2552\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1978\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2097\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2425\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2466\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2607\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3529\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3140\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2760\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2729\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2049\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2223\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2023\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2195\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1833\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1793\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1893\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1848\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2213\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2417\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2863\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2893\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2499\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2507\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2224\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1850\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1858\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2184\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2295\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2115\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2005\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2015\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1782\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2247\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2317\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2664\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1753\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2244\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2186\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2035\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1874\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2056\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1929\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1836\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2146\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1859\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1834\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2660\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2189\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1993\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2121\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2713\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2137\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2081\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1928\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.172 - 0s 13ms/step - loss: 0.1860\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1732\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1592\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1532\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1358\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1404\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1519\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1635\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1588\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1437\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1490\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1560\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2005\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2706\n",
      "Model: \"model_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_12 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_12 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 2.6191\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.5848\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.3225\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.1929\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.1280\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.8808\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.5494\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.1288\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.2676\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.9147\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.8989\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3172\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3932\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4629\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3054\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8765\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9036\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8634\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6389\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9551\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7485\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5634\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.1087\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5807\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4965\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5322\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8427\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4329\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4995\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4507\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5467\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5545\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4037\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5033\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5061\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7359\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4262\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4450\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3752\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3737\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4006\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4953\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3372\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7318\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3178\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3289\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4353\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3203\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2951\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2927\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3612\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3217\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2921\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3117\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3692\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4630\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3236\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3291\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3292\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3869\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3985\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2696\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2953\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2873\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3171\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2718\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3288\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3389\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4248\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2716\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2884\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2839\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2735\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3511\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3402\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2590\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2386\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3377\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2863\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2892\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2576\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2126\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2370\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3565\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2979\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3831\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2453\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2590\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2605\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2390\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2140\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2232\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2618\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2647\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2149\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2216\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3045\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2737\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2697\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2111\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1908\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1919\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2282\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2493\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3491\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3587\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2459\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1907\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1932\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1890\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2751\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3261\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2113\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2103\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2331\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1884\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2301\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1989\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2287\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2116\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1886\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1941\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2597\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2235\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2927\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2761\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1947\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1637\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1690\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1716\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1729\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1897\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2529\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2582\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1951\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1634\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1988\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1924\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2025\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1816\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1920\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2041\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2366\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1612\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1565\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1535\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1593\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1971\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2475\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2207\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2303\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1649\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1431\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1442\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1721\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2218\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2068\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1801\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1719\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1688\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1837\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1761\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1681\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2381\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2023\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1524\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1406\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1378\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1436\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1454\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2057\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2281\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1546\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1553\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1512\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1412\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1415\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2022\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1927\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1532\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1577\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1650\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1868\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1737\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1304\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1453\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2349\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1882\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1605\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1380\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1419\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1106\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1433\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1612\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1653\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1486\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1301\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1500\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2292\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1719\n",
      "Model: \"model_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_13 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_13 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 8.4068\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.5243\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.3599\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.1733\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.4323\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.3780\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.2715\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.7211\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.9595\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 4.0518\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.5260\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.6452\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.0626\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.5479\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.3581\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.7626\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 4.0053\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4750\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2621\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.2065\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3350\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.2212\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.5319\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1503\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.2444\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5470\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0426\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1517\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.6133\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8463\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9047\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5488\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7675\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7906\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2312\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0763\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6726\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6687\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8516\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5364\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7114\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0420\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7952\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8478\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8619\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5479\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7155\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4545\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7470\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8140\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5471\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6149\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3651\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4140\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5790\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5556\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7582\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4031\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3646\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5895\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8547\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3950\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3235\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3103\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2946\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4316\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5457\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5117\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4010\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3354\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2956\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3211\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4588\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3369\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3514\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4227\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4753\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3944\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4125\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3576\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4041\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3319\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2844\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3203\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4095\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3169\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3258\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3848\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2801\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2730\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3197\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3452\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3013\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2918\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3947\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2437\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3523\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3635\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4668\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3814\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3427\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2954\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2809\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2252\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2735\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3718\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3545\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2910\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2567\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2331\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2353\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2953\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2527\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2783\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4149\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3293\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2609\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2856\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2359\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2534\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2587\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2989\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2950\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3094\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2254\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2315\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2172\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2555\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3104\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4153\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2800\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2351\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2253\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2197\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2398\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2293\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2001\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2103\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2475\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3215\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2797\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2183\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2362\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2302\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2118\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2223\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2229\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2219\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2396\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2001\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2043\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1949\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2103\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3300\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2803\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2150\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1904\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1829\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1854\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2093\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2263\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2538\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2265\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2582\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2559\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2349\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2301\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2098\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2110\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1669\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1780\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1737\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1790\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1612\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1598\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1731\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2097\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2368\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1837\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2744\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2931\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2113\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1770\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1977\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1890\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1681\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2000\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2455\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2388\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1824\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2511\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2794\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3410\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2177\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1826\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1812\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1616\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1553\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1456\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1585\n",
      "Model: \"model_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_14 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_14 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 1.0315\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9310\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9681\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9517\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0119\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8923\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8559\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9016\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9066\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8220\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9819\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0925\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0362\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9480\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9290\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9495\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9421\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9221\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9824\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7669\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9280\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9784\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9881\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9279\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9456\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9685\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9221\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9268\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9321\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9179\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9849\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8592\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7517\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9394\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8919\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8326\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8605\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9940\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9174\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0058\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0072\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9937\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9609\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9612\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0114\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9161\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9381\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9024\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9411\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8679\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9224\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.0567\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9427\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8828\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9848\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8800\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9813\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8636\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9810\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8922\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9780\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9267\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8997\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8712\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8684\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8402\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9112\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7911\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8240\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7347\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3282\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9978\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9337\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9298\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9573\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9712\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9351\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9454\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9678\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7240\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6665\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7153\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7243\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6014\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7756\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7086\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5324\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5051\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8897\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5900\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5053\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5468\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9129\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5232\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7239\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4948\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5471\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7679\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5817\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5228\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6166\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6080\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5355\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5723\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5548\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5349\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6307\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5837\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4270\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4670\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4959\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6344\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5540\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5010\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5569\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6091\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4800\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5071\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5453\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5572\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4713\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4785\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5575\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6918\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4836\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5437\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5041\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5299\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4981\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5638\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5710\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4704\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4527\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5106\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5460\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4531\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5503\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4963\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4412\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5710\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4644\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4262\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5099\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5226\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4473\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4207\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4712\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5305\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4364\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4598\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4844\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4818\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4843\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4531\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5766\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4596\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4532\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5683\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4191\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4388\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3979\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4739\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4841\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4059\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4134\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4681\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4319\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3547\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3892\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3839\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5147\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4757\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3772\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3928\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3544\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4336\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4721\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4026\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4339\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4001\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4097\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4555\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.359 - 0s 7ms/step - loss: 0.3766\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3871\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4125\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4626\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3476\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4092\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3889\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3620\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3920\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3817\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3969\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3388\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3547\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4029\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3222\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3671\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4142\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3431\n",
      "Model: \"model_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_15 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_15 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 9ms/step - loss: 4.1205\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.5027\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.1634\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.8395\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.5553\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.6750\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.1973\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.8192\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.6122\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.6118\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.8625\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.6720\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.5745\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.5423\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.2744\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8478\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.2319\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.4733\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.1282\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.9100\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8401\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6055\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4334\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.5454\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4337\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1489\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2533\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4144\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.1580\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.6220\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9401\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9112\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8289\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1860\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9006\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1570\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8594\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9340\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9054\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7842\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8128\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7741\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9319\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9686\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6984\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6738\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7269\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9430\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7504\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7258\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6748\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6910\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6634\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7276\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7269\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6584\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6871\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7163\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6701\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6250\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6959\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6184\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6021\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6337\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6899\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7724\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6702\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6618\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6919\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7083\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6201\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6603\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6406\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5599\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5613\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5838\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6086\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5876\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5316\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5647\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5981\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5317\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6113\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5678\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5605\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5983\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5673\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6526\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4938\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4927\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5288\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6395\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5066\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4411\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4741\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4775\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4632\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4979\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5502\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4871\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4253\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5725\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4486\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4066\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4948\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5582\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5167\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3591\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3620\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4278\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4448\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3884\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3685\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5155\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5621\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3533\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4068\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4189\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3958\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3790\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4007\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3395\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3077\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3355\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4999\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4021\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2987\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2849\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3087\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4740\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3770\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3195\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3198\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3552\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2819\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3122\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4184\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3090\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2481\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2414\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2592\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2786\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3571\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4130\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2760\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2698\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3048\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2801\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2934\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2529\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2863\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2492\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2329\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2300\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2131\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2915\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3354\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3379\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2322\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2159\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2830\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2999\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2908\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2474\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2428\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2286\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2118\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2334\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2810\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4243\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2517\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1905\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1814\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2087\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2210\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2558\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2498\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2274\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1998\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2138\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2304\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2261\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1799\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1961\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2551\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2524\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1874\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2348\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2152\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2169\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1934\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1864\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1930\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1938\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1980\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1922\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1747\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1817\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2590\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2406\n",
      "Model: \"model_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_16 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_16 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 2s 7ms/step - loss: 6.3783\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 5.8727\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 3.7747\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.7553\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2.9634\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.9444\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.9740\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.6543\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.4953\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.4869\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 3.0093\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.6939\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.7138\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.4688\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.6196\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.3045\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.3003\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.1356\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.9047\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.0535\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.9789\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.7855\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.6699\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.5651\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.6538\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.5392\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.3522\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.6734\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.3242\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.6246\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.2825\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.3117\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.2201\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.2384\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.1908\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.1263\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.0178\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1216\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1692\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.1847\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.2879\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.1431\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.0315\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.0357\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9305\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9824\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0444\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9398\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9287\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0549\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8706\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9781\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9169\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9066\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7386\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0273\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9006\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7912\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7810\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7203\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7681\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.1711\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6959\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6448\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6732\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8508\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1732\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6898\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7257\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7309\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8055\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0031\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8455\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7201\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6191\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8619\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5980\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5827\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5139\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0331\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6492\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5131\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5814\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9550\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6154\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.7494\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5488\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5627\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5487\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4702\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4978\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9627\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9262\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4639\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4296\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3971\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4952\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0716\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4803\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4424\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5771\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6160\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5342\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4879\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3755\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4282\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5735\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4487\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4562\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6984\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5174\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4764\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4472\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4053\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3150\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3311\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4307\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5678\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7236\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3649\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3336\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3401\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4294\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4381\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5015\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4189\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3760\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2943\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2708\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3143\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4617\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5003\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4279\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3046\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2925\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3898\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3955\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3278\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3373\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3946\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3487\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3093\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3682\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3902\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3535\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3575\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3307\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2724\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3142\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3650\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3851\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3774\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3357\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3000\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2723\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3101\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4285\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5611\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3043\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2363\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2370\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2461\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2605\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2823\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3054\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2972\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3207\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3989\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4036\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3041\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2568\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2269\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2189\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2825\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3757\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3415\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2637\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2297\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3391\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3088\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2665\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2339\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2168\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2063\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2078\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2488\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4074\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4114\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3199\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2731\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2619\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2559\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2717\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3094\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2831\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2667\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2366\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2358\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2620\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2471\n",
      "Model: \"model_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_17 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_17 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 9ms/step - loss: 2.4139\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.4382\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.2160\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.2249\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.1616\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.0210\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.1138\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.3728\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.0630\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.2582\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.1613\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.2002\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.0107\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.1585\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.9045\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.9578\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.1565\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.8611\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.8796\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.1541\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.8986\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.8976\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.8974\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.8088\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.7412\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.6333\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.5617\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3381\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.7156\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.5294\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2277\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2915\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.8372\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0969\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2625\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7640\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0294\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4271\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2269\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8665\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0073\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.0395\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5457\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8227\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8135\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3213\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0876\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8664\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6970\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.7457\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.5512\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8741\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6769\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6619\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8426\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8360\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7052\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7750\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5829\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7629\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6505\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6868\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6430\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6206\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6925\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7931\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5714\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5490\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5659\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5995\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5713\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5140\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4913\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4758\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4842\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5371\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5619\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5650\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5129\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4704\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4149\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4409\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4941\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7031\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7386\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4408\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4324\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4696\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4511\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4188\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5137\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5337\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4311\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3764\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3826\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4026\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6451\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4358\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3541\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3613\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3491\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4022\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4810\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3817\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3338\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3630\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3254\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3034\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3085\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4264\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5066\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3957\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3291\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3056\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3127\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3543\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3392\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3268\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4062\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3348\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2880\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3397\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3101\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3147\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3386\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2960\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3238\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4119\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3241\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2616\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2501\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2990\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4144\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3338\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2681\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2430\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2617\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2365\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2304\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2524\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3157\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3290\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2895\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2601\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2623\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2895\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3303\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3010\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3293\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2749\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2347\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2402\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2468\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2483\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2881\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2550\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2178\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2174\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2143\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2711\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2114\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2011\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2016\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2557\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2825\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3968\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3026\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2145\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1956\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1946\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1913\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2115\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2173\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2126\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1913\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2457\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2244\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1893\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1988\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2312\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2223\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1913\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1885\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1981\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2011\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1938\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1930\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2214\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2323\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2490\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2712\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2471\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2238\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2193\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2332\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2156\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1804\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1882\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1882\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2000\n",
      "Model: \"model_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_18 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_18 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 2.2041\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.1318\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.0560\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.0949\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.0005\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.8640\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9837\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7304\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7848\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.8941\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3303\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.7324\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2179\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9997\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0763\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1161\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0408\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8845\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0100\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9830\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9869\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9348\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1933\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9053\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9075\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9702\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9634\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7969\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8380\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8299\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8075\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7277\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7037\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5226\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8034\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7576\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8160\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5403\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5631\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7000\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5300\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4442\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5242\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6168\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4461\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5229\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5252\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3419\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4579\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8531\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3798\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4586\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3465\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3805\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3651\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4615\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4680\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4850\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3492\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3187\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2979\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4750\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3362\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2964\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4146\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2992\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2822\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3614\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4279\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2872\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3415\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4628\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3865\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2946\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2817\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3912\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3031\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2774\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4009\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3032\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2779\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2574\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2475\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2543\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3784\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3780\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2516\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2359\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2681\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4529\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2591\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2849\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2773\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3407\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2592\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2538\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2486\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2357\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3238\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2944\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2721\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2542\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2881\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2597\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3007\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3052\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2269\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2096\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2036\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2933\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3623\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2266\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2208\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2762\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2952\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2247\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2508\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2461\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1877\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1889\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1824\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2992\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3537\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1931\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1834\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2160\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2030\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2531\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1879\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2497\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2319\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2098\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1842\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1584\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2185\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3537\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1869\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1813\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1828\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1773\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1603\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2002\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3127\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2138\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2278\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2069\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1703\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1664\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1721\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2163\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2355\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1657\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1589\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1587\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1868\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2069\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1753\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1920\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1649\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1722\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2225\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1838\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1635\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1947\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1972\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1714\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1983\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2418\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1714\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1702\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1453\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1462\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1720\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1990\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2027\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1458\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1741\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1555\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1689\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1613\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1530\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1403\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1582\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1867\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1432\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1424\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1495\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1850\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2283\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1553\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1368\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1269\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1438\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1473\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2051\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1762\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1350\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1210\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1212\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1302\n",
      "Model: \"model_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_19 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_19 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 6ms/step - loss: 7.3217\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 6.5312\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.1416\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 4.2474\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 4.6007\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 3.9573\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.5845\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.2411\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.6891\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 4.4606\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4.0148\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 3.4695\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.4043\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.4110\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.0504\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7490\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4278\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0592\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 3.8114\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.6597\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.2722\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1718\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1522\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1057\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3971\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.0507\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.0650\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4352\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0088\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1042\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9436\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1673\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8255\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8747\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0535\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0134\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8221\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8063\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7622\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7079\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6612\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9205\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7974\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8166\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5653\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5224\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6209\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1663\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6385\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4351\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5245\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6156\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7356\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4378\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4522\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5236\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4080\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4821\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7962\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5328\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4192\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3858\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3832\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3549\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5791\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5190\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4082\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3495\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3353\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4429\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7786\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3628\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3175\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3370\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3366\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4579\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4479\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3572\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3384\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3167\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3503\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3097\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3455\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3912\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4772\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4570\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3130\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2721\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3567\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3428\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3175\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3818\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4721\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3801\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2900\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2726\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3127\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4175\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4471\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3858\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3918\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2740\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3545\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3448\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2318\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2757\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2814\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4078\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3148\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2751\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3043\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2730\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2831\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2525\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2646\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2804\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3078\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2762\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2621\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3024\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4842\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4759\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3040\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2315\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2407\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2614\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2725\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2544\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2702\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2929\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2814\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3134\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3015\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3117\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3058\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3549\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2889\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3041\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2567\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2926\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2468\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2668\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3002\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3044\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3112\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2703\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2795\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2696\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2420\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2675\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2342\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2306\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2663\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2515\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3189\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2779\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2814\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2469\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2148\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2207\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2206\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2153\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2357\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2414\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2777\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2994\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4107\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3541\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2634\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2831\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2439\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2206\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2135\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2362\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2256\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1981\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2071\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2069\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2213\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2580\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2852\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2380\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2944\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2631\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2258\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2470\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2305\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1969\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1990\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2082\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2533\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2394\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1954\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1973\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1906\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2059\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2655\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4080\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2634\n",
      "Model: \"model_60\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_20 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_62\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_20 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 0.8736\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8554\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8885\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8992\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8938\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8061\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9003\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7588\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8414\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8694\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7763\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8318\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8565\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8341\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8056\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8738\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7637\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8657\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8975\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8790\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8341\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8704\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7873\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8071\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7690\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8448\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7571\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7151\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8232\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7947\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8469\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8167\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7967\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8116\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8218\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8837\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8240\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8812\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8094\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8531\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7846\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8784\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8297\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7741\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7687\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7232\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9968\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7594\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7406\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7065\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7868\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7174\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8329\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6880\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6629\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7469\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5417\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5315\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9257\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5521\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6021\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5838\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9294\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7447\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5393\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5436\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7385\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5011\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6355\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5593\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5740\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7477\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5478\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4354\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5038\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8339\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5662\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6004\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4762\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5733\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4542\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7224\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4896\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5269\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5277\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4434\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4807\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5005\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3987\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4780\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5164\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4014\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4954\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5533\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4681\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4531\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3884\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6774\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4261\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4815\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4254\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4824\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4622\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4348\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4079\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4477\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3952\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5020\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4401\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4476\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3727\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3611\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3671\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5032\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3716\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3730\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4632\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3610\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3997\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4971\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3869\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4395\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3780\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4626\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3692\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3177\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3813\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5203\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3436\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4296\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3105\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4208\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3704\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3214\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2888\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3064\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3986\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3501\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3593\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3279\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3568\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3609\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3100\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2881\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3397\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3924\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3520\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2869\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3802\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3253\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3007\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3290\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2881\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3279\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3817\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2759\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2985\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3145\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3081\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2788\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2550\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2631\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2632\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3024\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2879\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3747\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2823\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2493\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2489\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2685\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3086\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3449\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2533\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2433\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2721\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3396\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2765\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2652\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2761\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2308\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2499\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3303\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2628\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2743\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2524\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2452\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2810\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2693\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2773\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2588\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2626\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2575\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2468\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2123\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2479\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2504\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2233\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2385\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2631\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2477\n",
      "Model: \"model_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_21 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_21 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 4.4108\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.1748\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.8894\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.9782\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.6407\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8251\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7373\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7986\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8715\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.5783\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.6043\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.9862\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.1910\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.3767\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.3395\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.1354\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.1897\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.1720\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.8699\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6247\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.3248\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5219\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.8612\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.8634\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3488\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.8946\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1593\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5464\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4312\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2414\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2412\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1466\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0033\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4444\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3537\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9616\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0631\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9343\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8853\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9679\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0154\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9610\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0248\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8675\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.0239\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8390\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9325\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9524\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8320\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7997\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8075\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7492\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7357\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7258\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7261\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9548\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8275\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8032\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0287\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8713\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7249\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6811\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9691\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7454\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8112\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6669\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7539\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8433\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6643\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6950\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6447\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6267\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9385\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6302\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6147\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7121\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7370\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7043\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5616\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5255\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4995\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5774\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8822\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5651\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6157\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6644\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6613\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5069\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4518\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5364\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5357\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4981\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5161\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4662\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5639\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5379\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5132\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4619\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4993\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4157\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4840\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7183\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4353\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4402\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5245\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4355\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4133\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4641\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4145\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3923\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3989\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3898\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4277\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3249\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4371\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4602\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3562\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3315\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3269\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3639\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3862\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3281\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3460\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4283\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3970\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3109\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2564\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2753\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3338\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4815\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3466\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3359\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2937\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3060\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2911\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3473\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3891\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3392\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3512\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3320\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2635\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2632\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2570\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2342\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2802\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3794\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2789\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2957\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2625\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2956\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2928\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2621\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2826\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3221\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2673\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2604\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2469\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3132\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3300\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2820\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2498\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2548\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2882\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3247\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2469\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2524\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2727\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2222\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2542\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2489\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1971\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1916\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1968\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1994\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2183\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2601\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3013\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2286\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2144\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2259\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2299\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2191\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3264\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3174\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2665\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2299\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2084\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2249\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2291\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2141\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2111\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2354\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2240\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2018\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1885\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1751\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1795\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1906\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2144\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2315\n",
      "Model: \"model_66\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_22 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_67\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_68\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_22 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 10ms/step - loss: 6.7384\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 5.4819\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 3.7105\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 3.7186\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 3.4887\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.7756\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 3.0673\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 3.3013\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 3.1413\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.8297\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 3.1609\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.4765\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.5127\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.7064\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.7442\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.9699\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.9513\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.8563\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.9043\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.6275\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.1046\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.0551\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.6545\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.4283\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.7856\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4784\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.9656\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.3800\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.4930\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.4350\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2747\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3187\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3976\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3890\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4932\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3169\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2105\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3021\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2733\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4402\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2205\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2577\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1886\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2069\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1599\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3579\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2918\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1672\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1324\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0894\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3176\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1155\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0450\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1248\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1970\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.0571\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1549\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1107\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9920\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9829\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9736\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0420\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1698\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9119\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0825\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8969\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9394\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9892\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9542\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9341\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9618\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2838\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9164\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8365\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9304\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8240\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7647\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7235\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7790\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1724\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7909\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7513\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8286\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9517\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7755\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8448\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6474\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8604\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5639\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.280 - 0s 8ms/step - loss: 1.4691\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7800\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6180\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5110\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6904\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5679\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6017\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9003\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6940\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5479\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4956\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5643\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6423\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6199\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6651\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5951\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6443\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5226\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5332\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3548\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7321\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9231\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4747\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4160\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4711\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5880\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4896\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3803\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4311\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7785\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4633\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4983\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4899\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4983\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4344\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4530\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3851\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4018\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4780\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7020\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3672\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3771\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4091\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4176\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6108\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6122\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3862\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3421\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3454\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3579\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3665\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3371\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3162\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3385\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3782\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4683\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3852\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3320\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3598\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4335\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4241\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3076\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3309\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3992\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4185\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4285\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4183\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3609\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2974\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3124\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3926\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6958\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3622\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2969\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3252\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3554\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3148\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2830\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2666\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2655\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2854\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3591\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4313\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3124\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2846\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3550\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3822\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3186\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2937\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2994\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2837\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3080\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3747\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3299\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3259\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2760\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2767\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3508\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3654\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3419\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3313\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2627\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2461\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2751\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3259\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3207\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3541\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4340\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3811\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3316\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2568\n",
      "Model: \"model_69\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_23 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 254,736\n",
      "Trainable params: 254,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_70\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 51, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 26, 16)            96        \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 13, 32)            2592      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               106752    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "embed (Dense)                (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 127,183\n",
      "Trainable params: 127,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_71\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_input (InputLayer)   [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "blowup (Dense)               (None, 416)               106912    \n",
      "_________________________________________________________________\n",
      "unflatten (Reshape)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling1D)     (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "deconv0 (Conv1D)             (None, 26, 16)            2576      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling1D)     (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "output (Conv1D)              (None, 52, 1)             81        \n",
      "_________________________________________________________________\n",
      "cropping1d_23 (Cropping1D)   (None, 51, 1)             0         \n",
      "=================================================================\n",
      "Total params: 127,553\n",
      "Trainable params: 127,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 1.7398\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.7391\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6766\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6288\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8057\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.7263\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7252\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6537\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6719\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4314\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7662\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.5319\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3615\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.8938\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.8184\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6959\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.6821\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.7083\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.7374\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.6410\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.5384\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.6738\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5488\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4662\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.5187\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3542\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.8874\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.2261\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.138 - 0s 9ms/step - loss: 1.3234\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.3211\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1838\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0834\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.8749\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9956\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0784\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.4345\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1042\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9802\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.1497\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9580\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0169\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9881\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6868\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6249\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.1890\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8641\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7109\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.0190\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7583\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6376\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9210\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7020\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7484\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.882 - 0s 6ms/step - loss: 0.8987\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7988\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6723\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6106\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8215\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6276\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5999\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0033\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9175\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6224\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7722\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7007\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6974\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7475\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6308\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6129\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5987\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6266\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5760\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5596\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5531\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6912\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6840\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6068\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6956\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5116\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6192\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7267\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5381\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5291\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5160\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5904\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6076\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5266\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6339\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5829\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6652\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5264\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4667\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5282\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5716\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4334\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4492\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4843\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6593\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5072\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5004\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5239\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5724\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4817\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5716\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4937\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4790\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4444\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4544\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4426\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5740\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4339\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4268\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4317\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4348\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4927\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5329\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4343\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5272\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4280\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4315\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4209\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5922\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4443\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4113\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4388\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4945\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4247\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4645\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4563\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4621\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3809\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3990\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4502\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4967\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3899\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4109\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4699\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4659\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4507\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4357\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4123\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4233\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3833\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4179\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3670\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4212\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4854\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3894\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4233\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4768\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3784\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3484\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3421\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3360\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3588\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3435\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3605\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4230\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4077\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4215\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3280\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3085\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3734\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3998\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3465\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3455\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3973\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3658\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3567\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3529\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4419\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4046\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3420\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3409\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3127\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3555\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3903\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3128\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3611\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3468\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3504\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4017\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2961\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2957\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2908\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3125\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3106\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2880\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2922\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3141\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3577\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3473\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3400\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3072\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2807\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3020\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3576\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3091\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3031\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2984\n"
     ]
    }
   ],
   "source": [
    "mts_train.features, mts_test.features =  getPeaxFeatures(\n",
    "    mts_train.X.transpose([0, 2, 1]), \n",
    "    settings[dataset]['filters'],\n",
    "    settings[dataset]['kernels'],\n",
    "    feat_size = settings[dataset]['feat_size'], \n",
    "    epochs =settings[dataset]['epochs'], \n",
    "    batch_size = 64, \n",
    "    X_test=mts_test.X.transpose([0, 2, 1])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 360)\n"
     ]
    }
   ],
   "source": [
    "# print(mts.features.shape)\n",
    "X_repr = []\n",
    "\n",
    "for d in range(mts_train.D):\n",
    "    if len(X_repr) == 0:\n",
    "        X_repr = mts_train.features[:, d, :]\n",
    "    else:\n",
    "        X_repr = np.concatenate((X_repr, mts_train.features[:,d,:]), axis=1)\n",
    "        \n",
    "mts_train.features = X_repr\n",
    "\n",
    "X_repr = []\n",
    "\n",
    "for d in range(mts_test.D):\n",
    "    if len(X_repr) == 0:\n",
    "        X_repr = mts_test.features[:, d, :]\n",
    "    else:\n",
    "        X_repr = np.concatenate((X_repr, mts_test.features[:,d,:]), axis=1)\n",
    "        \n",
    "mts_test.features = X_repr\n",
    "print(mts_test.features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.8444444444444444\n",
      "0.8222222222222222\n",
      "f1 score\n",
      "0.8439265485945577\n",
      "0.8211276761143845\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(mts_train.features, mts_train.y)\n",
    "\n",
    "print('accuracy')\n",
    "print(clf.score(mts_train.features, mts_train.y))\n",
    "print(clf.score(mts_test.features, mts_test.y))\n",
    "\n",
    "print('f1 score')\n",
    "print(f1_score(clf.predict(mts_train.features), mts_train.y, average= 'weighted'))\n",
    "print(f1_score(clf.predict(mts_test.features), mts_test.y, average= 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/texs/anaconda3/envs/peax/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f40f8297640>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "\n",
    "# reducer = umap.UMAP(n_components=2, metric='cosine')\n",
    "reducer = umap.UMAP(n_components=2, metric='euclidean', n_neighbors=15)\n",
    "reducer.fit(mts_train.features, y=mts_train.y)\n",
    "coords_train = reducer.transform(mts_train.features)\n",
    "coords_test = reducer.transform(mts_test.features)\n",
    "\n",
    "plt.scatter(coords_train[:, 0], coords_train[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f40dabddb80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(coords_test[:, 0], coords_test[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/texs/Documentos/Repositories/mts_viz')\n",
    "from server.source.storage import MTSStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mts shape: N: 180 -  T: 51 - D: 48\n",
      "mts shape: N: 180 -  T: 51 - D: 48\n"
     ]
    }
   ],
   "source": [
    "storage = MTSStorage('mts_comparison')    \n",
    "# storage.delete()\n",
    "storage.load()\n",
    "\n",
    "# classLabels = {int(v): str(v) for v in np.unique(y)}\n",
    "dimensions = [str(dim) for dim in range(mts_train.D)]\n",
    "# dimensions = [sPoll, sPoll + '_norm']\n",
    "# dimensions = pollutants + [poll + '_norm' for poll in pollutants]\n",
    "data = np.concatenate([mts_train.X_orig, mts_train.X], axis=2) \n",
    "storage.add_mts(\n",
    "    '{}_peax_train'.format(dataset),\n",
    "    data, \n",
    "    dimensions = dimensions + [dim+ '_norm' for dim in dimensions], \n",
    "    labels = {'class': mts_train.y},\n",
    "    labelsNames = {'class': classLabels},\n",
    "    coords = {\n",
    "        'shape': coords_train,\n",
    "    },\n",
    "    sampling=True,\n",
    "    n_samples= 400\n",
    ")\n",
    "\n",
    "data = np.concatenate([mts_test.X_orig, mts_test.X], axis=2) \n",
    "storage.add_mts(\n",
    "    '{}_peax_test'.format(dataset),\n",
    "    data, \n",
    "    dimensions = dimensions + [dim+ '_norm' for dim in dimensions], \n",
    "    labels = {'class': mts_test.y},\n",
    "    labelsNames = {'class': classLabels},\n",
    "    coords = {\n",
    "        'shape': coords_test,\n",
    "    },\n",
    "    sampling=True,\n",
    "    n_samples= 400\n",
    ")\n",
    "\n",
    "\n",
    "storage.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
